{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "#encoding:utf-8\n",
    "# \n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lxml packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = '''\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "'''\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"The Dormouse's story\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.parent # 父节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'head'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>The Dormouse's story</b>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li class=\"element\">Foo</li>,\n",
       " <li class=\"element\">Bar</li>,\n",
       " <li class=\"element\">Jay</li>,\n",
       " <li class=\"element\">Foo</li>,\n",
       " <li class=\"element\">Bar</li>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup.find_all('li')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foo\n",
      "Bar\n",
      "Jay\n",
      "Foo\n",
      "Bar\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('li'):\n",
    "    print i.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['list']\n",
      "['list', 'list-small']\n"
     ]
    }
   ],
   "source": [
    "for _ in soup.find_all('ul'):\n",
    "    print _.get('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul class=\"list\" id=\"list-1\">\\n<li class=\"element\">Foo</li>\\n<li class=\"element\">Bar</li>\\n<li class=\"element\">Jay</li>\\n</ul>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('ul')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foo\n",
      "Bar\n",
      "Jay\n",
      "Foo\n",
      "Bar\n"
     ]
    }
   ],
   "source": [
    "for ul in soup.find_all('ul'):\n",
    "    for li in ul.find_all('li'):\n",
    "        print li.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"panel-body\">\\n<ul class=\"list\" id=\"list-1\">\\n<li class=\"element\">Foo</li>\\n<li class=\"element\">Bar</li>\\n<li class=\"element\">Jay</li>\\n</ul>\\n<ul class=\"list list-small\" id=\"list-2\">\\n<li class=\"element\">Foo</li>\\n<li class=\"element\">Bar</li>\\n</ul>\\n</div>]\n"
     ]
    }
   ],
   "source": [
    "print soup.find_all(attrs = {\"class\":\"panel-body\"}) # attrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list list-small\" id=\"list-2\">\\n<li class=\"element\">Foo</li>\\n<li class=\"element\">Bar</li>\\n</ul>]\n"
     ]
    }
   ],
   "source": [
    "print soup.find_all(attrs = {'id':'list-2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li class=\"element\">Foo</li>,\n",
       " <li class=\"element\">Bar</li>,\n",
       " <li class=\"element\">Jay</li>,\n",
       " <li class=\"element\">Foo</li>,\n",
       " <li class=\"element\">Bar</li>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(attrs = {'class':'element'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foo\n",
      "Bar\n",
      "Jay\n",
      "Foo\n",
      "Bar\n"
     ]
    }
   ],
   "source": [
    "for _ in soup.find_all('li'):\n",
    "    print _.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li class=\"element\">Foo</li>,\n",
       " <li class=\"element\">Bar</li>,\n",
       " <li class=\"element\">Jay</li>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select \n",
    "html='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <ul class=\"list\" id=\"list-1\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "            <li class=\"element\">Jay</li>\n",
    "        </ul>\n",
    "        <ul class=\"list list-small\" id=\"list-2\">\n",
    "            <li class=\"element\">Foo</li>\n",
    "            <li class=\"element\">Bar</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# .等价与class , class.panel/class.panel-heading\n",
    "soup.select('.panel .panel-body #list-1 .element')  # “#” = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list-1\n",
      "list-2\n"
     ]
    }
   ],
   "source": [
    "for u1 in soup.select('ul'):\n",
    "    print u1['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hello\n",
      "\n",
      "\n",
      "\n",
      "Foo\n",
      "Bar\n",
      "Jay\n",
      "\n",
      "\n",
      "Foo\n",
      "Bar\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b class=\"boldest\">Extremely bold</b>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs 将复杂html文档转换成一个复杂的属性结构\n",
    "soup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\n",
    "tag  = soup.b \n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b class=\"boldest\">Extremely bold</b>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(attrs = {'class':'boldest'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely bold\n"
     ]
    }
   ],
   "source": [
    "print soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boldest']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['boldest']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b class=\"boldest\">Extremely bold</b>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag  # tag 的操作方法与字典一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body', 'strikeout']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多值属性\n",
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>')\n",
    "css_soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Back to the <a rel=\"index\">homepage</a></p>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将tag 转成字符串时，多值属性会合并成一个值\n",
    "rel_soup = BeautifulSoup('<p>Back to the <a rel=\"index\">homepage</a></p>')\n",
    "rel_soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a rel=\"index\">homepage</a>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a rel=\"index\">homepage</a>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_soup.p.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_soup.a['rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Back to the homepage'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'homepage'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_soup.a.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Extremely bold'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_soup.p.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><b class=\"boldest\">Extremely bold</b></body></html>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Honeywell'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.string.replace_with('Honeywell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Honeywell'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movieTop 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding=utf-8\n",
    "import requests\n",
    "import re\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import Workbook\n",
    "wb        = Workbook()\n",
    "dest_filename = 'movies.xlsx'\n",
    "ws1       = wb.active\n",
    "ws1.title = \"doubanmoviestop250\"\n",
    "DOWNLOAD_URL = 'http://movie.douban.com/top250/'\n",
    "\n",
    "def download_page(url):\n",
    "    \"\"\"获取url地址页面内容\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'\n",
    "    }\n",
    "    data = requests.get(url, headers=headers).content\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_li(doc):\n",
    "    soup = BeautifulSoup(doc, 'html.parser')\n",
    "    ol   = soup.find('ol', class_='grid_view')\n",
    "    name = []  # 名字\n",
    "    star_con = []  # 评价人数\n",
    "    score = []  # 评分\n",
    "    info_list = []  # 短评\n",
    "    for i in ol.find_all('li'):\n",
    "        detail = i.find('div', attrs={'class': 'hd'})\n",
    "        movie_name = detail.find(\n",
    "            'span', attrs={'class': 'title'}).get_text()  # 电影名字\n",
    "        level_star = i.find(\n",
    "            'span', attrs={'class': 'rating_num'}).get_text()  # 评分\n",
    "        star = i.find('div', attrs={'class': 'star'})\n",
    "        star_num = star.find(text=re.compile('评价'))  # 评价\n",
    "\n",
    "        info = i.find('span', attrs={'class': 'inq'})  # 短评\n",
    "        if info:  # 判断是否有短评\n",
    "            info_list.append(info.get_text())\n",
    "        else:\n",
    "            info_list.append('无')\n",
    "        \n",
    "        score.append(level_star)\n",
    "        name.append(movie_name)\n",
    "        star_con.append(star_num)\n",
    "    page = soup.find('span', attrs={'class': 'next'}).find('a')  # 获取下一页\n",
    "    if page:\n",
    "        return name, star_con, score, info_list, DOWNLOAD_URL + page['href']\n",
    "    return name, star_con, score, info_list, None\n",
    "\n",
    "\n",
    "def main():\n",
    "    url = DOWNLOAD_URL\n",
    "    name = []\n",
    "    star_con = []\n",
    "    score = []\n",
    "    info = []\n",
    "    while url:\n",
    "        doc = download_page(url)\n",
    "        movie, star, level_num, info_list, url = get_li(doc)\n",
    "        name = name + movie\n",
    "        star_con = star_con + star\n",
    "        score = score + level_num\n",
    "        info = info + info_list\n",
    "    for (i, m, o, p) in zip(name, star_con, score, info):\n",
    "        col_A = 'A%s' % (name.index(i) + 1)\n",
    "        col_B = 'B%s' % (name.index(i) + 1)\n",
    "        col_C = 'C%s' % (name.index(i) + 1)\n",
    "        col_D = 'D%s' % (name.index(i) + 1)\n",
    "        ws1[col_A] = i\n",
    "        ws1[col_B] = m\n",
    "        ws1[col_C] = o\n",
    "        ws1[col_D] = p\n",
    "    wb.save(filename=dest_filename)\n",
    "    print \"Done\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取每个元素的位置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = ['a','b','c']\n",
    "c = ['Honewed','hellowordl','this']\n",
    "for (i,j,k)in zip(c,b,a):\n",
    "    print c.index(i) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = download_page(DOWNLOAD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬取想要的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def GetUrlFromWeb(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    URLData = requests.get(url,headers = headers).content\n",
    "    return URLData\n",
    "\n",
    "def ExtractDataFromHtml(url):\n",
    "    WebPageLink = 'http://movie.douban.com/top250/'\n",
    "    Titles     = []\n",
    "    RatingNums = []\n",
    "    Quotes     = []\n",
    "    soup      = BeautifulSoup(url,'lxml')\n",
    "    tag_ol    = soup.find('ol',attrs = {\"class\":\"grid_view\"})\n",
    "    for li in tag_ol.find_all('li'):\n",
    "        # movie's title\n",
    "        hd    = li.find('div',attrs =  {'class':'hd'})\n",
    "        movietitles = hd.find('span',attrs = {'class':'title'}).get_text()\n",
    "    \n",
    "        #movie's rating num  \n",
    "        bd    = li.find('div',attrs =  {'class':'bd'})  \n",
    "        ratingnum  = bd.find('span',attrs = {'class':'rating_num'}).get_text()      \n",
    "        Titles.append(movietitles)\n",
    "        RatingNums.append(ratingnum)\n",
    "        \n",
    "        #movie's comments/quote\n",
    "        quote  = bd.find('p',attrs = {'class':\"quote\"})\n",
    "        if quote:\n",
    "            Quotes.append(quote.get_text())\n",
    "        else:\n",
    "            Quotes.append(\"No comments\")\n",
    "    # next page avaiable url \n",
    "    nextpagetail  = soup.find('span',attrs = {\"class\":\"next\"}).find('a')\n",
    "    if nextpagetail:\n",
    "        return Titles,RatingNums,Quotes,WebPageLink + nextpagetail.get('href')\n",
    "    else: \n",
    "        return Titles,RatingNums,Quotes,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# inputs data \n",
    "from openpyxl import Workbook\n",
    "wb        = Workbook()\n",
    "wb_       = wb.active\n",
    "wb_.title   = \"Top250Movies\"\n",
    "filename    = \"Top250Movies.xlsx\"\n",
    "WebPageLink = 'http://movie.douban.com/top250/'\n",
    "TitlesIndex = []\n",
    "#----\n",
    "def main(URL):\n",
    "    Titles     = []\n",
    "    RatingNums = []\n",
    "    Quotes     = []\n",
    "    while URL:\n",
    "        URLData    = GetUrlFromWeb(URL)\n",
    "        Title,RatingNum,Quote,URL = ExtractDataFromHtml(URLData)\n",
    "        Titles     = Titles + Title\n",
    "        RatingNums = RatingNums + RatingNum\n",
    "        Quotes     = Quotes + Quote\n",
    "        \n",
    "    for (i,j,k) in zip(Titles,RatingNums,Quotes):\n",
    "        Titles_column     = 'A%s' %(Titles.index(i) + 1)       # column A \n",
    "        RatingNums_column = 'B%s' %(Titles.index(i) + 1)       # column B\n",
    "        Quotes_column     = 'C%s' %(Titles.index(i) + 1)       # column C\n",
    "        wb_[Titles_column]     = i\n",
    "        wb_[RatingNums_column] = j\n",
    "        wb_[Quotes_column]     = k\n",
    "        TitlesIndex.append(Titles_column)  # used to log column index \n",
    "    wb.save(filename = filename)           # wb = Workbook()\n",
    "    print \"Completed and Saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed and Saved\n"
     ]
    }
   ],
   "source": [
    "URL        = WebPageLink\n",
    "if __name__ == \"__main__\":\n",
    "    main(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27', 'A28', 'A29', 'A30', 'A31', 'A32', 'A33', 'A34', 'A35', 'A36', 'A37', 'A38', 'A39', 'A40', 'A41', 'A42', 'A43', 'A44', 'A45', 'A46', 'A47', 'A48', 'A49', 'A50', 'A51', 'A52', 'A53', 'A54', 'A55', 'A56', 'A57', 'A58', 'A59', 'A60', 'A61', 'A62', 'A63', 'A64', 'A65', 'A66', 'A67', 'A68', 'A69', 'A70', 'A71', 'A72', 'A73', 'A74', 'A75', 'A76', 'A77', 'A78', 'A79', 'A80', 'A81', 'A82', 'A83', 'A84', 'A85', 'A86', 'A87', 'A88', 'A89', 'A90', 'A91', 'A92', 'A93', 'A94', 'A95', 'A96', 'A97', 'A98', 'A99', 'A100', 'A101', 'A102', 'A103', 'A104', 'A105', 'A106', 'A107', 'A108', 'A109', 'A110', 'A111', 'A112', 'A113', 'A114', 'A115', 'A116', 'A117', 'A118', 'A119', 'A120', 'A121', 'A122', 'A123', 'A124', 'A125', 'A126', 'A127', 'A128', 'A129', 'A130', 'A131', 'A132', 'A133', 'A134', 'A135', 'A136', 'A137', 'A138', 'A139', 'A140', 'A141', 'A142', 'A143', 'A144', 'A145', 'A146', 'A147', 'A148', 'A149', 'A150', 'A151', 'A152', 'A153', 'A154', 'A155', 'A156', 'A157', 'A158', 'A159', 'A160', 'A161', 'A162', 'A163', 'A164', 'A165', 'A166', 'A167', 'A168', 'A169', 'A170', 'A171', 'A172', 'A173', 'A174', 'A175', 'A176', 'A177', 'A178', 'A179', 'A180', 'A181', 'A182', 'A183', 'A184', 'A185', 'A186', 'A187', 'A188', 'A189', 'A190', 'A191', 'A192', 'A193', 'A194', 'A195', 'A196', 'A197', 'A198', 'A199', 'A200', 'A201', 'A202', 'A203', 'A204', 'A205', 'A206', 'A207', 'A208', 'A209', 'A210', 'A211', 'A212', 'A213', 'A214', 'A215', 'A216', 'A217', 'A218', 'A219', 'A220', 'A221', 'A222', 'A223', 'A224', 'A225', 'A226', 'A227', 'A228', 'A229', 'A230', 'A231', 'A232', 'A233', 'A234', 'A235', 'A236', 'A237', 'A238', 'A239', 'A240', 'A241', 'A242', 'A243', 'A244', 'A245', 'A246', 'A247', 'A248', 'A249', 'A250']\n"
     ]
    }
   ],
   "source": [
    "print TitlesIndex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好世界\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "st = \"hello,world!!%[545]你好234世界。。。\"\n",
    "ste = re.sub(\"[A-Za-z0-9\\!\\%\\[\\]\\,\\。]\", \"\", st)\n",
    "print(ste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
